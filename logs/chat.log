2025-04-19 22:47:16,599 - docs_llm_scraper.commands.chat - INFO - Using provider model ID: accounts/fireworks/models/llama-v3p1-8b-instruct
2025-04-19 22:47:16,601 - docs_llm_scraper.llama_agent.agent - INFO - Initializing LlamaAgent with LLM model=accounts/fireworks/models/llama-v3p1-8b-instruct, embedding model=all-MiniLM-L6-v2
2025-04-19 22:47:22,611 - docs_llm_scraper.llama_agent.agent - INFO - Checking available embedding models...
2025-04-19 22:47:22,621 - docs_llm_scraper.llama_agent.client - INFO - Using embedding model: all-MiniLM-L6-v2 with 384 dimensions
2025-04-19 22:47:22,626 - docs_llm_scraper.llama_agent.client - INFO - Found existing vector database: docs_assistant
2025-04-19 22:47:22,627 - docs_llm_scraper.llama_agent.client - INFO - Using existing vector database (force_embedding_model is disabled)
2025-04-19 22:47:22,637 - docs_llm_scraper.llama_agent.ingestion - INFO - Ingesting 116 documentation chunks…
2025-04-19 22:47:22,638 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Sample chunk metadata before insertion: {'document_id': 'en-latest-distributions-self-hosted-distro-ollama-html--000', 'slug': 'en-latest-distributions-self-hosted-distro-ollama-html--000', 'page': 'pages/en-latest-distributions-self-hosted-distro-ollama-html.md', 'position': 0, 'mime_type': 'text/markdown', 'token_count': 1306}
2025-04-19 22:47:22,638 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Metadata keys: ['document_id', 'slug', 'page', 'position', 'mime_type', 'token_count']
2025-04-19 22:47:22,638 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: token_count value: 1306
2025-04-19 22:47:22,638 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Chunk has token_count?: True
2025-04-19 22:47:22,638 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Chunk object type: Chunk
2025-04-19 22:47:22,638 - docs_llm_scraper.llama_agent.ingestion - INFO - Chunk statistics: 116 chunks, avg length: 4318.8 chars, min: 139, max: 10669
2025-04-19 22:47:48,358 - docs_llm_scraper.llama_agent.ingestion - INFO - Chunk ingestion complete. 116 chunks embedded.
2025-04-19 22:47:48,358 - docs_llm_scraper.llama_agent.ingestion - INFO - Configured model may differ from actual model used.
2025-04-19 22:47:48,358 - docs_llm_scraper.llama_agent.ingestion - INFO - Requested model: all-MiniLM-L6-v2, LlamaStack is using: all-MiniLM-L6-v2
2025-04-19 22:47:48,358 - docs_llm_scraper.llama_agent.ingestion - INFO - To force using a specific model, set FORCE_EMBEDDING_MODEL=true in your .env file.
2025-04-19 22:47:48,358 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Testing vector store retrieval to check metadata preservation
2025-04-19 22:47:48,603 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Retrieved chunk metadata: {'document_id': 'en-latest-building-applications-tools-html--001', 'page': 'pages/en-latest-building-applications-tools-html.md', 'slug': 'en-latest-building-applications-tools-html--001', 'position': 1.0, 'mime_type': 'text/markdown'}
2025-04-19 22:47:48,604 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Retrieved metadata keys: ['document_id', 'page', 'slug', 'position', 'mime_type']
2025-04-19 22:47:48,604 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Has token_count?: False
2025-04-19 22:47:48,604 - docs_llm_scraper.llama_agent.agent - INFO - Patching vector_io.query to handle missing token_count fields
2025-04-19 22:47:48,604 - docs_llm_scraper.llama_agent.agent - INFO - Using direct result handling instead of monkey patching
2025-04-19 22:48:25,391 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting direct query to vector store
2025-04-19 22:48:25,391 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Searching vector store for: 'Please help me implement a basic llama stack app with ollama'
2025-04-19 22:48:25,391 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Available methods on vector_io: ['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_client', '_delete', '_get', '_get_api_list', '_original_query', '_patch', '_post', '_put', '_sleep', 'insert', 'query', 'with_raw_response', 'with_streaming_response']
2025-04-19 22:48:25,391 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting vector_io.query with minimal parameters
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Found 3 direct results for query: 'Please help me implement a basic llama stack app with ollama'
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using embedding model: all-MiniLM-L6-v2
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 document_id: en-latest-getting-started-index-html--000
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 slug: en-latest-getting-started-index-html--000
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 page: pages/en-latest-getting-started-index-html.md
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 document_id: en-latest-getting-started-index-html--000
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 slug: en-latest-getting-started-index-html--000
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 page: pages/en-latest-getting-started-index-html.md
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 document_id: en-latest-getting-started-index-html--000
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 slug: en-latest-getting-started-index-html--000
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 page: pages/en-latest-getting-started-index-html.md
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - Search Results Summary:
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - Rank  Score      Length  Document                                 Preview                                                     
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - ------------------------------------------------------------------------------------------------------------------------
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - 1     N/A        6336    en-latest-getting-started-index-html--000  # Quickstart  Get started with Llama Stack in minutes!  Lla
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - 2     N/A        6336    en-latest-getting-started-index-html--000  # Quickstart  Get started with Llama Stack in minutes!  Lla
2025-04-19 22:48:25,414 - docs_llm_scraper.llama_agent.agent - INFO - 3     N/A        6336    en-latest-getting-started-index-html--000  # Quickstart  Get started with Llama Stack in minutes!  Lla
2025-04-19 22:48:33,383 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Processing agent response
2025-04-19 22:48:33,384 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Response type: Turn
2025-04-19 22:48:33,384 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Response attributes: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'completed_at', 'construct', 'copy', 'dict', 'from_orm', 'input_messages', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_attachments', 'output_message', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'session_id', 'started_at', 'steps', 'to_dict', 'to_json', 'turn_id', 'update_forward_refs', 'validate']
2025-04-19 22:48:33,384 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: output_message present: True
2025-04-19 22:48:33,384 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: output_message type: CompletionMessage
2025-04-19 22:48:33,384 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: output_message attrs: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content', 'copy', 'dict', 'from_orm', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'parse_file', 'parse_obj', 'parse_raw', 'role', 'schema', 'schema_json', 'stop_reason', 'to_dict', 'to_json', 'tool_calls', 'update_forward_refs', 'validate']
2025-04-19 22:48:33,384 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using output_message.content
2025-04-19 22:49:16,876 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting direct query to vector store
2025-04-19 22:49:16,876 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Searching vector store for: 'What are the reccomended ways of setting up RAG in llama stack?'
2025-04-19 22:49:16,876 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Available methods on vector_io: ['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_client', '_delete', '_get', '_get_api_list', '_original_query', '_patch', '_post', '_put', '_sleep', 'insert', 'query', 'with_raw_response', 'with_streaming_response']
2025-04-19 22:49:16,876 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting vector_io.query with minimal parameters
2025-04-19 22:49:16,920 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Found 3 direct results for query: 'What are the reccomended ways of setting up RAG in llama stack?'
2025-04-19 22:49:16,920 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using embedding model: all-MiniLM-L6-v2
2025-04-19 22:49:16,920 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 document_id: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 22:49:16,920 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 slug: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 22:49:16,920 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 page: pages/en-latest-sources-getting-started-index-md-txt.md
2025-04-19 22:49:16,920 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 document_id: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 22:49:16,920 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 slug: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 22:49:16,920 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 page: pages/en-latest-sources-getting-started-index-md-txt.md
2025-04-19 22:49:16,920 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 document_id: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 22:49:16,920 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 slug: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 22:49:16,920 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 page: pages/en-latest-sources-getting-started-index-md-txt.md
2025-04-19 22:49:16,921 - docs_llm_scraper.llama_agent.agent - INFO - Search Results Summary:
2025-04-19 22:49:16,921 - docs_llm_scraper.llama_agent.agent - INFO - Rank  Score      Length  Document                                 Preview                                                     
2025-04-19 22:49:16,921 - docs_llm_scraper.llama_agent.agent - INFO - ------------------------------------------------------------------------------------------------------------------------
2025-04-19 22:49:16,921 - docs_llm_scraper.llama_agent.agent - INFO - 1     N/A        6235    en-latest-sources-getting-started-index-md-txt--000  # Quickstart  Get started with Llama Stack in minutes!  Lla
2025-04-19 22:49:16,921 - docs_llm_scraper.llama_agent.agent - INFO - 2     N/A        6235    en-latest-sources-getting-started-index-md-txt--000  # Quickstart  Get started with Llama Stack in minutes!  Lla
2025-04-19 22:49:16,921 - docs_llm_scraper.llama_agent.agent - INFO - 3     N/A        6235    en-latest-sources-getting-started-index-md-txt--000  # Quickstart  Get started with Llama Stack in minutes!  Lla
2025-04-19 22:49:19,215 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Processing agent response
2025-04-19 22:49:19,216 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Response type: Turn
2025-04-19 22:49:19,216 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Response attributes: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'completed_at', 'construct', 'copy', 'dict', 'from_orm', 'input_messages', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_attachments', 'output_message', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'session_id', 'started_at', 'steps', 'to_dict', 'to_json', 'turn_id', 'update_forward_refs', 'validate']
2025-04-19 22:49:19,217 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: output_message present: True
2025-04-19 22:49:19,217 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: output_message type: CompletionMessage
2025-04-19 22:49:19,217 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: output_message attrs: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content', 'copy', 'dict', 'from_orm', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'parse_file', 'parse_obj', 'parse_raw', 'role', 'schema', 'schema_json', 'stop_reason', 'to_dict', 'to_json', 'tool_calls', 'update_forward_refs', 'validate']
2025-04-19 22:49:19,217 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using output_message.content
2025-04-19 22:54:37,268 - docs_llm_scraper.commands.chat - INFO - Using provider model ID: accounts/fireworks/models/llama-v3p1-8b-instruct
2025-04-19 22:54:37,270 - docs_llm_scraper.llama_agent.agent - INFO - Initializing LlamaAgent with LLM model=accounts/fireworks/models/llama-v3p1-8b-instruct, embedding model=all-MiniLM-L6-v2
2025-04-19 22:54:42,987 - docs_llm_scraper.llama_agent.agent - INFO - Checking available embedding models...
2025-04-19 22:54:42,993 - docs_llm_scraper.llama_agent.client - INFO - Using embedding model: all-MiniLM-L6-v2 with 384 dimensions
2025-04-19 22:54:42,995 - docs_llm_scraper.llama_agent.client - INFO - Found existing vector database: docs_assistant
2025-04-19 22:54:42,995 - docs_llm_scraper.llama_agent.client - INFO - Using existing vector database (force_embedding_model is disabled)
2025-04-19 22:54:43,004 - docs_llm_scraper.llama_agent.ingestion - INFO - Ingesting 116 documentation chunks…
2025-04-19 22:54:43,004 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Sample chunk metadata before insertion: {'document_id': 'en-latest-distributions-self-hosted-distro-ollama-html--000', 'slug': 'en-latest-distributions-self-hosted-distro-ollama-html--000', 'page': 'pages/en-latest-distributions-self-hosted-distro-ollama-html.md', 'position': 0, 'mime_type': 'text/markdown', 'token_count': 1306}
2025-04-19 22:54:43,004 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Metadata keys: ['document_id', 'slug', 'page', 'position', 'mime_type', 'token_count']
2025-04-19 22:54:43,004 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: token_count value: 1306
2025-04-19 22:54:43,004 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Chunk has token_count?: True
2025-04-19 22:54:43,004 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Chunk object type: Chunk
2025-04-19 22:54:43,004 - docs_llm_scraper.llama_agent.ingestion - INFO - Chunk statistics: 116 chunks, avg length: 4318.8 chars, min: 139, max: 10669
2025-04-19 22:55:06,588 - docs_llm_scraper.llama_agent.ingestion - INFO - Chunk ingestion complete. 116 chunks embedded.
2025-04-19 22:55:06,588 - docs_llm_scraper.llama_agent.ingestion - INFO - Configured model may differ from actual model used.
2025-04-19 22:55:06,588 - docs_llm_scraper.llama_agent.ingestion - INFO - Requested model: all-MiniLM-L6-v2, LlamaStack is using: all-MiniLM-L6-v2
2025-04-19 22:55:06,592 - docs_llm_scraper.llama_agent.ingestion - INFO - To force using a specific model, set FORCE_EMBEDDING_MODEL=true in your .env file.
2025-04-19 22:55:06,593 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Testing vector store retrieval to check metadata preservation
2025-04-19 22:55:06,854 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Retrieved chunk metadata: {'document_id': 'en-latest-building-applications-tools-html--001', 'page': 'pages/en-latest-building-applications-tools-html.md', 'slug': 'en-latest-building-applications-tools-html--001', 'position': 1.0, 'mime_type': 'text/markdown'}
2025-04-19 22:55:06,854 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Retrieved metadata keys: ['document_id', 'page', 'slug', 'position', 'mime_type']
2025-04-19 22:55:06,854 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Has token_count?: False
2025-04-19 22:55:06,855 - docs_llm_scraper.llama_agent.agent - INFO - Patching vector_io.query to handle missing token_count fields
2025-04-19 22:55:06,855 - docs_llm_scraper.llama_agent.agent - INFO - Using direct result handling instead of monkey patching
2025-04-19 22:56:17,606 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting direct query to vector store
2025-04-19 22:56:17,606 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Searching vector store for: 'Please help me write a basic llama stack demo server'
2025-04-19 22:56:17,606 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Available methods on vector_io: ['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_client', '_delete', '_get', '_get_api_list', '_original_query', '_patch', '_post', '_put', '_sleep', 'insert', 'query', 'with_raw_response', 'with_streaming_response']
2025-04-19 22:56:17,606 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting vector_io.query with minimal parameters
2025-04-19 22:56:17,626 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Found 3 direct results for query: 'Please help me write a basic llama stack demo server'
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using embedding model: all-MiniLM-L6-v2
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 document_id: en-latest-references-index-html--000
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 slug: en-latest-references-index-html--000
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 page: pages/en-latest-references-index-html.md
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 document_id: en-latest-references-index-html--000
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 slug: en-latest-references-index-html--000
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 page: pages/en-latest-references-index-html.md
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 document_id: en-latest-references-index-html--000
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 slug: en-latest-references-index-html--000
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 page: pages/en-latest-references-index-html.md
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - Search Results Summary:
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - Rank  Score      Length  Document                                 Preview                                                     
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - ------------------------------------------------------------------------------------------------------------------------
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - 1     N/A        446     en-latest-references-index-html--000      # References  * [API Reference](api_reference/index.html) f
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - 2     N/A        446     en-latest-references-index-html--000      # References  * [API Reference](api_reference/index.html) f
2025-04-19 22:56:17,627 - docs_llm_scraper.llama_agent.agent - INFO - 3     N/A        446     en-latest-references-index-html--000      # References  * [API Reference](api_reference/index.html) f
2025-04-19 22:56:18,547 - docs_llm_scraper.llama_agent.agent - WARNING - KeyError for token_count, attempting to synthesize response from chunks...
2025-04-19 22:56:18,547 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Found 1 unique chunks for synthesis
2025-04-19 22:56:18,548 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Added document 1 for synthesis
2025-04-19 22:56:18,548 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using LLM to synthesize response from chunks
2025-04-19 22:56:20,969 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Successfully synthesized response from chunks
2025-04-19 23:14:48,176 - docs_llm_scraper.commands.chat - INFO - Using provider model ID: accounts/fireworks/models/llama-v3p1-8b-instruct
2025-04-19 23:14:48,782 - docs_llm_scraper.llama_agent.agent - INFO - Initializing LlamaAgent with LLM model=accounts/fireworks/models/llama-v3p1-8b-instruct, embedding model=all-MiniLM-L6-v2
2025-04-19 23:15:04,299 - docs_llm_scraper.llama_agent.agent - INFO - Checking available embedding models...
2025-04-19 23:15:04,308 - docs_llm_scraper.llama_agent.client - INFO - Using embedding model: all-MiniLM-L6-v2 with 384 dimensions
2025-04-19 23:15:04,311 - docs_llm_scraper.llama_agent.client - INFO - Found existing vector database: docs_assistant
2025-04-19 23:15:04,311 - docs_llm_scraper.llama_agent.client - INFO - Using existing vector database (force_embedding_model is disabled)
2025-04-19 23:15:04,821 - docs_llm_scraper.llama_agent.ingestion - INFO - Ingesting 116 documentation chunks…
2025-04-19 23:15:04,821 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Sample chunk metadata before insertion: {'document_id': 'en-latest-distributions-self-hosted-distro-ollama-html--000', 'slug': 'en-latest-distributions-self-hosted-distro-ollama-html--000', 'page': 'pages/en-latest-distributions-self-hosted-distro-ollama-html.md', 'position': 0, 'mime_type': 'text/markdown', 'token_count': 1306}
2025-04-19 23:15:04,821 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Metadata keys: ['document_id', 'slug', 'page', 'position', 'mime_type', 'token_count']
2025-04-19 23:15:04,821 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: token_count value: 1306
2025-04-19 23:15:04,821 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Chunk has token_count?: True
2025-04-19 23:15:04,821 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Chunk object type: Chunk
2025-04-19 23:15:04,821 - docs_llm_scraper.llama_agent.ingestion - INFO - Chunk statistics: 116 chunks, avg length: 4318.8 chars, min: 139, max: 10669
2025-04-19 23:15:36,532 - docs_llm_scraper.llama_agent.ingestion - INFO - Chunk ingestion complete. 116 chunks embedded.
2025-04-19 23:15:36,532 - docs_llm_scraper.llama_agent.ingestion - INFO - Configured model may differ from actual model used.
2025-04-19 23:15:36,532 - docs_llm_scraper.llama_agent.ingestion - INFO - Requested model: all-MiniLM-L6-v2, LlamaStack is using: all-MiniLM-L6-v2
2025-04-19 23:15:36,532 - docs_llm_scraper.llama_agent.ingestion - INFO - To force using a specific model, set FORCE_EMBEDDING_MODEL=true in your .env file.
2025-04-19 23:15:36,532 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Testing vector store retrieval to check metadata preservation
2025-04-19 23:15:36,818 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Retrieved chunk metadata: {'document_id': 'en-latest-building-applications-tools-html--001', 'page': 'pages/en-latest-building-applications-tools-html.md', 'slug': 'en-latest-building-applications-tools-html--001', 'position': 1.0, 'mime_type': 'text/markdown'}
2025-04-19 23:15:36,818 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Retrieved metadata keys: ['document_id', 'page', 'slug', 'position', 'mime_type']
2025-04-19 23:15:36,818 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Has token_count?: False
2025-04-19 23:15:37,220 - docs_llm_scraper.llama_agent.agent - INFO - Patching vector_io.query to handle missing token_count fields
2025-04-19 23:15:37,220 - docs_llm_scraper.llama_agent.agent - INFO - Using direct result handling instead of monkey patching
2025-04-19 23:15:55,009 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting direct query to vector store
2025-04-19 23:15:55,009 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Searching vector store for: 'Please help me build a simple llama-stack server'
2025-04-19 23:15:55,009 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Available methods on vector_io: ['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_client', '_delete', '_get', '_get_api_list', '_original_query', '_patch', '_post', '_put', '_sleep', 'insert', 'query', 'with_raw_response', 'with_streaming_response']
2025-04-19 23:15:55,009 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting vector_io.query with minimal parameters
2025-04-19 23:15:55,069 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Found 3 direct results for query: 'Please help me build a simple llama-stack server'
2025-04-19 23:15:55,069 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using embedding model: all-MiniLM-L6-v2
2025-04-19 23:15:55,069 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 document_id: en-latest-references-index-html--000
2025-04-19 23:15:55,069 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 slug: en-latest-references-index-html--000
2025-04-19 23:15:55,069 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 page: pages/en-latest-references-index-html.md
2025-04-19 23:15:55,069 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 document_id: en-latest-references-index-html--000
2025-04-19 23:15:55,069 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 slug: en-latest-references-index-html--000
2025-04-19 23:15:55,069 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 page: pages/en-latest-references-index-html.md
2025-04-19 23:15:55,070 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 document_id: en-latest-references-index-html--000
2025-04-19 23:15:55,070 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 slug: en-latest-references-index-html--000
2025-04-19 23:15:55,071 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 page: pages/en-latest-references-index-html.md
2025-04-19 23:15:55,071 - docs_llm_scraper.llama_agent.agent - INFO - Search Results Summary:
2025-04-19 23:15:55,071 - docs_llm_scraper.llama_agent.agent - INFO - Rank  Score      Length  Document                                 Preview                                                     
2025-04-19 23:15:55,071 - docs_llm_scraper.llama_agent.agent - INFO - ------------------------------------------------------------------------------------------------------------------------
2025-04-19 23:15:55,071 - docs_llm_scraper.llama_agent.agent - INFO - 1     N/A        446     en-latest-references-index-html--000      # References  * [API Reference](api_reference/index.html) f
2025-04-19 23:15:55,071 - docs_llm_scraper.llama_agent.agent - INFO - 2     N/A        446     en-latest-references-index-html--000      # References  * [API Reference](api_reference/index.html) f
2025-04-19 23:15:55,071 - docs_llm_scraper.llama_agent.agent - INFO - 3     N/A        446     en-latest-references-index-html--000      # References  * [API Reference](api_reference/index.html) f
2025-04-19 23:15:56,418 - docs_llm_scraper.llama_agent.agent - WARNING - KeyError for token_count, attempting to synthesize response from chunks...
2025-04-19 23:15:56,419 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Found 1 unique chunks for synthesis
2025-04-19 23:15:56,419 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Added document 1 for synthesis
2025-04-19 23:15:56,419 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using LLM to synthesize response from chunks
2025-04-19 23:15:59,055 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Successfully synthesized response from chunks
2025-04-19 23:16:27,037 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting direct query to vector store
2025-04-19 23:16:27,037 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Searching vector store for: 'Can you give me some exaxmples of doing it programatically?'
2025-04-19 23:16:27,038 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Available methods on vector_io: ['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_client', '_delete', '_get', '_get_api_list', '_original_query', '_patch', '_post', '_put', '_sleep', 'insert', 'query', 'with_raw_response', 'with_streaming_response']
2025-04-19 23:16:27,038 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting vector_io.query with minimal parameters
2025-04-19 23:16:27,092 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Found 3 direct results for query: 'Can you give me some exaxmples of doing it programatically?'
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using embedding model: all-MiniLM-L6-v2
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 document_id: en-latest-building-applications-index-html--000
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 slug: en-latest-building-applications-index-html--000
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 page: pages/en-latest-building-applications-index-html.md
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 document_id: en-latest-building-applications-index-html--000
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 slug: en-latest-building-applications-index-html--000
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 page: pages/en-latest-building-applications-index-html.md
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 document_id: en-latest-building-applications-index-html--000
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 slug: en-latest-building-applications-index-html--000
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 page: pages/en-latest-building-applications-index-html.md
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - Search Results Summary:
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - Rank  Score      Length  Document                                 Preview                                                     
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - ------------------------------------------------------------------------------------------------------------------------
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - 1     N/A        1292    en-latest-building-applications-index-html--000  # Building AI Applications (Examples)  Llama Stack provides
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - 2     N/A        1292    en-latest-building-applications-index-html--000  # Building AI Applications (Examples)  Llama Stack provides
2025-04-19 23:16:27,093 - docs_llm_scraper.llama_agent.agent - INFO - 3     N/A        1292    en-latest-building-applications-index-html--000  # Building AI Applications (Examples)  Llama Stack provides
2025-04-19 23:16:30,440 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Processing agent response
2025-04-19 23:16:30,440 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Response type: Turn
2025-04-19 23:16:30,440 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Response attributes: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'completed_at', 'construct', 'copy', 'dict', 'from_orm', 'input_messages', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'output_attachments', 'output_message', 'parse_file', 'parse_obj', 'parse_raw', 'schema', 'schema_json', 'session_id', 'started_at', 'steps', 'to_dict', 'to_json', 'turn_id', 'update_forward_refs', 'validate']
2025-04-19 23:16:30,440 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: output_message present: True
2025-04-19 23:16:30,441 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: output_message type: CompletionMessage
2025-04-19 23:16:30,441 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: output_message attrs: ['__abstractmethods__', '__annotations__', '__class__', '__class_getitem__', '__class_vars__', '__copy__', '__deepcopy__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__fields__', '__fields_set__', '__format__', '__ge__', '__get_pydantic_core_schema__', '__get_pydantic_json_schema__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__pretty__', '__private_attributes__', '__pydantic_complete__', '__pydantic_computed_fields__', '__pydantic_core_schema__', '__pydantic_custom_init__', '__pydantic_decorators__', '__pydantic_extra__', '__pydantic_fields__', '__pydantic_fields_set__', '__pydantic_generic_metadata__', '__pydantic_init_subclass__', '__pydantic_parent_namespace__', '__pydantic_post_init__', '__pydantic_private__', '__pydantic_root_model__', '__pydantic_serializer__', '__pydantic_setattr_handlers__', '__pydantic_validator__', '__reduce__', '__reduce_ex__', '__replace__', '__repr__', '__repr_args__', '__repr_name__', '__repr_recursion__', '__repr_str__', '__rich_repr__', '__setattr__', '__setstate__', '__sizeof__', '__slots__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_calculate_keys', '_copy_and_set_values', '_get_value', '_iter', '_setattr_handler', 'construct', 'content', 'copy', 'dict', 'from_orm', 'json', 'model_computed_fields', 'model_config', 'model_construct', 'model_copy', 'model_dump', 'model_dump_json', 'model_extra', 'model_fields', 'model_fields_set', 'model_json_schema', 'model_parametrized_name', 'model_post_init', 'model_rebuild', 'model_validate', 'model_validate_json', 'model_validate_strings', 'parse_file', 'parse_obj', 'parse_raw', 'role', 'schema', 'schema_json', 'stop_reason', 'to_dict', 'to_json', 'tool_calls', 'update_forward_refs', 'validate']
2025-04-19 23:16:30,441 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using output_message.content
2025-04-19 23:16:54,673 - docs_llm_scraper.commands.chat - INFO - Using provider model ID: accounts/fireworks/models/llama-v3p1-8b-instruct
2025-04-19 23:16:55,279 - docs_llm_scraper.llama_agent.agent - INFO - Initializing LlamaAgent with LLM model=accounts/fireworks/models/llama-v3p1-8b-instruct, embedding model=all-MiniLM-L6-v2
2025-04-19 23:17:01,647 - docs_llm_scraper.llama_agent.agent - INFO - Checking available embedding models...
2025-04-19 23:17:01,657 - docs_llm_scraper.llama_agent.client - INFO - Using embedding model: all-MiniLM-L6-v2 with 384 dimensions
2025-04-19 23:17:01,660 - docs_llm_scraper.llama_agent.client - INFO - Found existing vector database: docs_assistant
2025-04-19 23:17:01,660 - docs_llm_scraper.llama_agent.client - INFO - Using existing vector database (force_embedding_model is disabled)
2025-04-19 23:17:02,172 - docs_llm_scraper.llama_agent.ingestion - INFO - Ingesting 116 documentation chunks…
2025-04-19 23:17:02,173 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Sample chunk metadata before insertion: {'document_id': 'en-latest-distributions-self-hosted-distro-ollama-html--000', 'slug': 'en-latest-distributions-self-hosted-distro-ollama-html--000', 'page': 'pages/en-latest-distributions-self-hosted-distro-ollama-html.md', 'position': 0, 'mime_type': 'text/markdown', 'token_count': 1306}
2025-04-19 23:17:02,173 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Metadata keys: ['document_id', 'slug', 'page', 'position', 'mime_type', 'token_count']
2025-04-19 23:17:02,173 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: token_count value: 1306
2025-04-19 23:17:02,173 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Chunk has token_count?: True
2025-04-19 23:17:02,173 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Chunk object type: Chunk
2025-04-19 23:17:02,173 - docs_llm_scraper.llama_agent.ingestion - INFO - Chunk statistics: 116 chunks, avg length: 4318.8 chars, min: 139, max: 10669
2025-04-19 23:17:28,506 - docs_llm_scraper.llama_agent.ingestion - INFO - Chunk ingestion complete. 116 chunks embedded.
2025-04-19 23:17:28,506 - docs_llm_scraper.llama_agent.ingestion - INFO - Configured model may differ from actual model used.
2025-04-19 23:17:28,506 - docs_llm_scraper.llama_agent.ingestion - INFO - Requested model: all-MiniLM-L6-v2, LlamaStack is using: all-MiniLM-L6-v2
2025-04-19 23:17:28,506 - docs_llm_scraper.llama_agent.ingestion - INFO - To force using a specific model, set FORCE_EMBEDDING_MODEL=true in your .env file.
2025-04-19 23:17:28,506 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Testing vector store retrieval to check metadata preservation
2025-04-19 23:17:28,725 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Retrieved chunk metadata: {'document_id': 'en-latest-building-applications-tools-html--001', 'page': 'pages/en-latest-building-applications-tools-html.md', 'slug': 'en-latest-building-applications-tools-html--001', 'position': 1.0, 'mime_type': 'text/markdown'}
2025-04-19 23:17:28,726 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Retrieved metadata keys: ['document_id', 'page', 'slug', 'position', 'mime_type']
2025-04-19 23:17:28,726 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Has token_count?: False
2025-04-19 23:17:29,127 - docs_llm_scraper.llama_agent.agent - INFO - Patching vector_io.query to handle missing token_count fields
2025-04-19 23:17:29,127 - docs_llm_scraper.llama_agent.agent - INFO - Using direct result handling instead of monkey patching
2025-04-19 23:18:16,930 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting direct query to vector store
2025-04-19 23:18:16,930 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Searching vector store for: 'Hello! Can you help me build a simple llama stack server using ollama?'
2025-04-19 23:18:16,930 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Available methods on vector_io: ['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_client', '_delete', '_get', '_get_api_list', '_original_query', '_patch', '_post', '_put', '_sleep', 'insert', 'query', 'with_raw_response', 'with_streaming_response']
2025-04-19 23:18:16,930 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting vector_io.query with minimal parameters
2025-04-19 23:18:16,990 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Found 3 direct results for query: 'Hello! Can you help me build a simple llama stack server using ollama?'
2025-04-19 23:18:16,990 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using embedding model: all-MiniLM-L6-v2
2025-04-19 23:18:16,990 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 document_id: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 23:18:16,991 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 slug: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 23:18:16,991 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 page: pages/en-latest-sources-getting-started-index-md-txt.md
2025-04-19 23:18:16,991 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 document_id: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 23:18:16,991 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 slug: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 23:18:16,991 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 page: pages/en-latest-sources-getting-started-index-md-txt.md
2025-04-19 23:18:16,991 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 document_id: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 23:18:16,991 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 slug: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 23:18:16,991 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 page: pages/en-latest-sources-getting-started-index-md-txt.md
2025-04-19 23:18:16,992 - docs_llm_scraper.llama_agent.agent - INFO - Search Results Summary:
2025-04-19 23:18:16,992 - docs_llm_scraper.llama_agent.agent - INFO - Rank  Score      Length  Document                                 Preview                                                     
2025-04-19 23:18:16,992 - docs_llm_scraper.llama_agent.agent - INFO - ------------------------------------------------------------------------------------------------------------------------
2025-04-19 23:18:16,992 - docs_llm_scraper.llama_agent.agent - INFO - 1     N/A        6235    en-latest-sources-getting-started-index-md-txt--000  # Quickstart  Get started with Llama Stack in minutes!  Lla
2025-04-19 23:18:16,992 - docs_llm_scraper.llama_agent.agent - INFO - 2     N/A        6235    en-latest-sources-getting-started-index-md-txt--000  # Quickstart  Get started with Llama Stack in minutes!  Lla
2025-04-19 23:18:16,992 - docs_llm_scraper.llama_agent.agent - INFO - 3     N/A        6235    en-latest-sources-getting-started-index-md-txt--000  # Quickstart  Get started with Llama Stack in minutes!  Lla
2025-04-19 23:18:17,892 - docs_llm_scraper.llama_agent.agent - WARNING - KeyError for token_count, attempting to synthesize response from chunks...
2025-04-19 23:18:17,892 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Found 1 unique chunks for synthesis
2025-04-19 23:18:17,892 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Added document 1 for synthesis
2025-04-19 23:18:17,892 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using LLM to synthesize response from chunks
2025-04-19 23:18:26,787 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Successfully synthesized response from chunks
2025-04-19 23:27:02,693 - docs_llm_scraper.commands.chat - INFO - Using provider model ID: accounts/fireworks/models/llama-v3p1-8b-instruct
2025-04-19 23:27:03,295 - docs_llm_scraper.llama_agent.agent - INFO - Initializing LlamaAgent with LLM model=accounts/fireworks/models/llama-v3p1-8b-instruct, embedding model=all-MiniLM-L6-v2
2025-04-19 23:27:10,586 - docs_llm_scraper.llama_agent.agent - INFO - Checking available embedding models...
2025-04-19 23:27:10,601 - docs_llm_scraper.llama_agent.client - INFO - Using embedding model: all-MiniLM-L6-v2 with 384 dimensions
2025-04-19 23:27:10,605 - docs_llm_scraper.llama_agent.client - INFO - Found existing vector database: docs_assistant
2025-04-19 23:27:10,605 - docs_llm_scraper.llama_agent.client - INFO - Using existing vector database (force_embedding_model is disabled)
2025-04-19 23:27:11,115 - docs_llm_scraper.llama_agent.ingestion - INFO - Ingesting 116 documentation chunks…
2025-04-19 23:27:11,115 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Sample chunk metadata before insertion: {'document_id': 'en-latest-distributions-self-hosted-distro-ollama-html--000', 'slug': 'en-latest-distributions-self-hosted-distro-ollama-html--000', 'page': 'pages/en-latest-distributions-self-hosted-distro-ollama-html.md', 'position': 0, 'mime_type': 'text/markdown', 'token_count': 1306}
2025-04-19 23:27:11,115 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Metadata keys: ['document_id', 'slug', 'page', 'position', 'mime_type', 'token_count']
2025-04-19 23:27:11,115 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: token_count value: 1306
2025-04-19 23:27:11,115 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Chunk has token_count?: True
2025-04-19 23:27:11,115 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Chunk object type: Chunk
2025-04-19 23:27:11,116 - docs_llm_scraper.llama_agent.ingestion - INFO - Chunk statistics: 116 chunks, avg length: 4318.8 chars, min: 139, max: 10669
2025-04-19 23:27:40,435 - docs_llm_scraper.llama_agent.ingestion - INFO - Chunk ingestion complete. 116 chunks embedded.
2025-04-19 23:27:40,435 - docs_llm_scraper.llama_agent.ingestion - INFO - Configured model may differ from actual model used.
2025-04-19 23:27:40,435 - docs_llm_scraper.llama_agent.ingestion - INFO - Requested model: all-MiniLM-L6-v2, LlamaStack is using: all-MiniLM-L6-v2
2025-04-19 23:27:40,435 - docs_llm_scraper.llama_agent.ingestion - INFO - To force using a specific model, set FORCE_EMBEDDING_MODEL=true in your .env file.
2025-04-19 23:27:40,435 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Testing vector store retrieval to check metadata preservation
2025-04-19 23:27:40,698 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Retrieved chunk metadata: {'document_id': 'en-latest-building-applications-tools-html--001', 'page': 'pages/en-latest-building-applications-tools-html.md', 'slug': 'en-latest-building-applications-tools-html--001', 'position': 1.0, 'mime_type': 'text/markdown'}
2025-04-19 23:27:40,699 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Retrieved metadata keys: ['document_id', 'page', 'slug', 'position', 'mime_type']
2025-04-19 23:27:40,699 - docs_llm_scraper.llama_agent.ingestion - INFO - DIAGNOSTIC: Has token_count?: False
2025-04-19 23:27:41,100 - docs_llm_scraper.llama_agent.agent - INFO - Patching vector_io.query to handle missing token_count fields
2025-04-19 23:27:41,100 - docs_llm_scraper.llama_agent.agent - INFO - Using direct result handling instead of monkey patching
2025-04-19 23:28:02,033 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting direct query to vector store
2025-04-19 23:28:02,034 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Searching vector store for: 'Please help me build an example llama-stack server using Ollama as the provider'
2025-04-19 23:28:02,035 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Available methods on vector_io: ['__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_client', '_delete', '_get', '_get_api_list', '_original_query', '_patch', '_post', '_put', '_sleep', 'insert', 'query', 'with_raw_response', 'with_streaming_response']
2025-04-19 23:28:02,035 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Attempting vector_io.query with minimal parameters
2025-04-19 23:28:02,104 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Found 3 direct results for query: 'Please help me build an example llama-stack server using Ollama as the provider'
2025-04-19 23:28:02,105 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using embedding model: all-MiniLM-L6-v2
2025-04-19 23:28:02,105 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 document_id: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 23:28:02,105 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 slug: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 23:28:02,105 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 1 page: pages/en-latest-sources-getting-started-index-md-txt.md
2025-04-19 23:28:02,105 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 document_id: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 23:28:02,105 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 slug: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 23:28:02,105 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 2 page: pages/en-latest-sources-getting-started-index-md-txt.md
2025-04-19 23:28:02,105 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 document_id: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 23:28:02,105 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 slug: en-latest-sources-getting-started-index-md-txt--000
2025-04-19 23:28:02,106 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Result 3 page: pages/en-latest-sources-getting-started-index-md-txt.md
2025-04-19 23:28:02,106 - docs_llm_scraper.llama_agent.agent - INFO - Search Results Summary:
2025-04-19 23:28:02,106 - docs_llm_scraper.llama_agent.agent - INFO - Rank  Score      Length  Document                                 Preview                                                     
2025-04-19 23:28:02,106 - docs_llm_scraper.llama_agent.agent - INFO - ------------------------------------------------------------------------------------------------------------------------
2025-04-19 23:28:02,106 - docs_llm_scraper.llama_agent.agent - INFO - 1     N/A        6235    en-latest-sources-getting-started-index-md-txt--000  # Quickstart  Get started with Llama Stack in minutes!  Lla
2025-04-19 23:28:02,106 - docs_llm_scraper.llama_agent.agent - INFO - 2     N/A        6235    en-latest-sources-getting-started-index-md-txt--000  # Quickstart  Get started with Llama Stack in minutes!  Lla
2025-04-19 23:28:02,106 - docs_llm_scraper.llama_agent.agent - INFO - 3     N/A        6235    en-latest-sources-getting-started-index-md-txt--000  # Quickstart  Get started with Llama Stack in minutes!  Lla
2025-04-19 23:28:06,255 - docs_llm_scraper.llama_agent.agent - WARNING - KeyError for token_count, attempting to synthesize response from chunks...
2025-04-19 23:28:06,256 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Found 1 unique chunks for synthesis
2025-04-19 23:28:06,256 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Added document 1 for synthesis
2025-04-19 23:28:06,256 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Using LLM to synthesize response from chunks
2025-04-19 23:28:08,704 - docs_llm_scraper.llama_agent.agent - INFO - DIAGNOSTIC: Successfully synthesized response from chunks
